##################################### Wide Camera + Laser Control (1920x1440 pixels) #####################################
import cv2
import numpy as np
import math
import socket
import threading
import time
import sys
from flask import Flask, jsonify, request, Response
from typing import Tuple, List

# For Jupyter/IPython compatibility
try:
    sys.stdout.reconfigure(line_buffering=True)
    sys.stderr.reconfigure(line_buffering=True)
except AttributeError:
    pass

# --- DAC/Voltage Configuration ---
DAC_MAX = 1920
AO_RANGE = 5.0

# --- Network Configuration ---
HOST = '127.0.0.1'
PORT = 65432
daq_socket = None

# Web server for tablet
TABLET_SERVER_PORT = 8081
SERVER_IP = '0.0.0.0'

# --- Rotation Configuration ---
ROTATION_ANGLE_DEG = 0  # Rotation angle in degrees
ROTATION_ANGLE_RAD = np.radians(ROTATION_ANGLE_DEG)
ROTATION_CENTER_X = 960  # Center of 1920x1440
ROTATION_CENTER_Y = 720

# --- Drawing Configuration ---
MIN_DIST = 2              
MIN_JUMP_DIST = 10        
CLOSED_THRESHOLD = 100    
AREA_STEP = 10
SINGLE_POINT_THRESHOLD = 20

# --- Dark Spot Detection Configuration ---
GLOBAL_GRAYSCALE_THRESHOLD = 80
WINDOW_NAME = "Laser Controller"
MIN_AREA = 500
MAX_AREA = 500000

# --- Galvo Configuration (adjusted for 1920x1440) ---
HOME_X = 960
HOME_Y = 720
GALVO_MIN_X = 125
GALVO_MAX_X = 1750
GALVO_MIN_Y = 0
GALVO_MAX_Y = 1333
CROSS_SIZE = 10

# --- Global State ---
contours = []
finished_polys = []
last_active_contour = None
detected_contours = []
current = []
drawing = False
LASER_ON_TIME_MS = 5.0  # default dwell time per point (ms)
laser_time_lock = threading.Lock()

# Video Streaming State
video_lock = threading.Lock()
output_frame = None

# Touch state
touch_active = False
touch_start_pos = None
touch_current_path = []

# --- CALIBRATION STATE ---
CALIBRATION_PIXEL_POINTS = []
CALIBRATION_DATA_MAP = []
MANUAL_CALIBRATION_MODE = False

contour_lock = threading.Lock()
socket_lock = threading.Lock()

# Global reference to camera capture
cap = None
running = True

# --- Area preview (density-based) ---
area_preview_points = []
area_preview_lock = threading.Lock()

# --- Flask App for Tablet Interface ---
app = Flask(__name__)

@app.before_request

def log_request_info():
    print(f"\n>>> INCOMING REQUEST: {request.method} {request.path}", flush=True)

# HTML Interface
TABLET_HTML = """
<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
<meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
<meta http-equiv="Pragma" content="no-cache">
<meta http-equiv="Expires" content="0">
<style>
body {
    margin: 0;
    background: #000;
    color: #0f0;
    font-family: monospace;
    overflow: hidden;
}
#touchpad {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    z-index: 10;
    touch-action: none;
}
#video-background {
    position: absolute;
    width: 100%;
    height: 100%;
    object-fit: contain;
}
.sidebar {
    position: absolute;
    right: 20px;
    top: 20px;
    bottom: 20px;
    display: flex;
    flex-direction: column;
    gap: 15px;
    z-index: 25;
}
.btn {
    width: 120px;
    height: 80px;
    background: rgba(0,0,0,0.85);
    border: 3px solid #0f0;
    display: flex;
    align-items: center;
    justify-content: center;
    border-radius: 15px;
    font-weight: bold;
    font-size: 24px;
    cursor: pointer;
    color: #0f0;
    transition: all 0.2s;
}
.btn:active {
    transform: scale(0.95);
    background: rgba(0,255,0,0.2);
}
.btn-exit {
    border-color: #ff0;
    color: #ff0;
}
.btn-exit:active {
    background: rgba(255,255,0,0.2);
}
.btn-lase {
    border-color: #f00;
    color: #f00;
    font-size: 22px;
}
.btn-lase:active {
    background: rgba(255,0,0,0.2);
}
.slider-container {
    width: 120px;
    background: rgba(0,0,0,0.85);
    border: 3px solid #0f0;
    border-radius: 15px;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    padding: 15px 0;
    gap: 10px;
}
.slider-label {
    font-size: 18px;
    color: #0f0;
    font-weight: bold;
}
input[type=range][orient=vertical] {
    -webkit-appearance: slider-vertical;
    width: 40px;
    height: 200px;
    cursor: pointer;
}
.slider-value {
    font-size: 28px;
    color: #fff;
    font-weight: bold;
}
</style>
</head>
<body>
<img id="video-background" src="/video_feed">
<div id="touchpad"></div>
<div class="sidebar">
    <div class="btn btn-lase" onclick="cmd('lasing')">LASING</div>
    <div class="slider-container">
        <div class="slider-label">DENSITY</div>
        <input type="range" min="5" max="100" step="5" value="10"
               orient="vertical" oninput="updateDensity(this.value)">
        <div class="slider-value" id="dval">10</div>
    </div>
    <div class="slider-container">
        <div class="slider-label">THRESH</div>
        <input type="range" min="0" max="255" value="80" 
               orient="vertical" oninput="updateThresh(this.value)">
        <div class="slider-value" id="tval">80</div>
    </div>
    <div class="slider-container">
        <div class="slider-label">DWELL (ms)</div>
        <input type="range" min="0.5" max="20" step="0.5" value="5"
            orient="vertical" oninput="updateDwell(this.value)">
        <div class="slider-value" id="dwellval">5</div>
    </div>

    <div class="btn" onclick="cmd('calibrate')">CALIB</div>
    <div class="btn" onclick="cmd('home')">HOME</div>
    <div class="btn" onclick="cmd('clear')">CLEAR</div>
    <div class="btn btn-exit" onclick="cmd('exit')">EXIT</div>
</div>
<script>
function updateDwell(v) {
    document.getElementById('dwellval').innerText = v;
    fetch('/update_dwell', {
        method:'POST',
        headers:{'Content-Type':'application/json'},
        body: JSON.stringify({ DWELL_MS: parseFloat(v) })
    });
}
function cmd(c) {
    fetch('/command', {method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({command:c})})
    .then(response => response.json())
    .then(data => console.log("Response:", data))
    .catch(error => console.error("Error:", error));
}
function updateThresh(v) {
    document.getElementById('tval').innerText = v;
    fetch('/update_threshold', {method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({threshold:parseInt(v)})});
}
function updateDensity(v) {
    document.getElementById('dval').innerText = v;
    fetch('/update_density', {method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({density:parseInt(v)})});
}
const tp = document.getElementById('touchpad');
function send(t, cx, cy) {
    const r = tp.getBoundingClientRect();
    const x = Math.round(((cx - r.left)/r.width)*1920);
    const y = Math.round(((cy - r.top)/r.height)*1440);
    fetch('/touch_input', {method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({touching:t, x:x, y:y})});
}
tp.addEventListener('touchstart', (e)=>{ e.preventDefault(); send(true, e.touches[0].clientX, e.touches[0].clientY); });
tp.addEventListener('touchmove', (e)=>{ e.preventDefault(); send(true, e.touches[0].clientX, e.touches[0].clientY); });
tp.addEventListener('touchend', ()=>{ send(false, 0, 0); });
</script>
</body>
</html>
"""

def generate_web_stream():
    global output_frame
    last_frame_time = 0
    fps_limit = 1/20
    
    while True:
        current_time = time.time()
        if current_time - last_frame_time < fps_limit:
            time.sleep(0.03)
            continue
        
        with video_lock:
            if output_frame is None:
                continue
            encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 30]
            flag, encodedImage = cv2.imencode(".jpg", output_frame, encode_param)
            if not flag:
                continue
        
        last_frame_time = current_time
        yield(b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + bytearray(encodedImage) + b'\r\n')

@app.route('/')
def tablet_interface():
    return TABLET_HTML

@app.route("/video_feed")
def video_feed():
    return Response(generate_web_stream(), mimetype="multipart/x-mixed-replace; boundary=frame")

@app.route('/command', methods=['POST'])
def handle_ui_command():
    global running, CALIBRATION_PIXEL_POINTS, detected_contours, daq_socket
    global finished_polys, last_active_contour, current, contours, AREA_STEP, area_preview_points
    
    data = request.json
    cmd = data.get('command')
    print(f"\n[COMMAND] {cmd.upper()}", flush=True)
    
    if cmd == 'lasing':
        print("[LASING] ========== START ==========", flush=True)
        
        # Check 1: Active contour?
        if last_active_contour is None:
            print("[LASING] âŒ No active contour", flush=True)
            return jsonify({'status': 'error', 'msg': 'No contour'})
        print(f"[LASING] âœ“ Contour: {last_active_contour.shape}", flush=True)
        
        # Check 2: Preview points?
        with area_preview_lock:
            area_pts = list(area_preview_points)
        
        if len(area_pts) == 0:
            print(f"[LASING] âŒ No preview points (AREA_STEP={AREA_STEP})", flush=True)
            return jsonify({'status': 'error', 'msg': 'Empty preview'})
        print(f"[LASING] âœ“ Points: {len(area_pts)}", flush=True)
        
        # Check 3: DAQ connected?
        if daq_socket is None:
            print("[LASING] âŒ No DAQ connection", flush=True)
            return jsonify({'status': 'error', 'msg': 'No DAQ'})
        print("[LASING] âœ“ DAQ connected", flush=True)
        
        # Send
        print(f"[LASING] â†’ Sending to server...", flush=True)
        try:
            send_lasing_to_server(area_pts, daq_socket, DWELL_MS=LASER_ON_TIME_MS)
            print(f"[LASING] âœ“ SUCCESS", flush=True)
            print("[LASING] ========== END ==========\n", flush=True)
        except Exception as e:
            print(f"[LASING] âŒ Exception: {e}", flush=True)
            import traceback
            traceback.print_exc()
            
    elif cmd == 'home':
        if daq_socket:
            with socket_lock:
                rotated = rotate_point(HOME_X, HOME_Y, ROTATION_ANGLE_RAD, ROTATION_CENTER_X, ROTATION_CENTER_Y)
                daq_socket.sendall(f"{int(rotated[0])},{int(rotated[1])}\n".encode('ascii'))
                print(f"[HOME] Sent: {rotated}", flush=True)
    
    elif cmd == 'clear':
        with contour_lock:
            finished_polys.clear()
            contours.clear()
            current = []
            last_active_contour = None
        with area_preview_lock:
            area_preview_points.clear()
        print("[CLEAR] All cleared including preview", flush=True)
    
    elif cmd == 'calibrate':
        threading.Thread(target=calibrate_galvo_camera, daemon=True).start()
    
    elif cmd == 'exit':
        running = False
    
    return jsonify({'status': 'ok'})

@app.route('/update_dwell', methods=['POST'])
def update_dwell():
    global LASER_ON_TIME_MS
    val = request.json.get('DWELL_MS', 5.0)
    LASER_ON_TIME_MS = float(np.clip(val, 0.1, 50.0))  
    print(f"[DWELL] Updated to {LASER_ON_TIME_MS} ms", flush=True)
    return jsonify({'status': 'ok', 'DWELL_MS': LASER_ON_TIME_MS})

@app.route('/touch_input', methods=['POST'])
def receive_touch():
    data = request.json
    touching, x, y = data.get('touching'), data.get('x'), data.get('y')
    
    if touching:
        if not touch_active:
            handle_touch_down(x, y)
        else:
            handle_touch_move(x, y)
    elif touch_active:
        handle_touch_up(x, y)
    
    return jsonify({'status': 'ok'})

@app.route('/update_threshold', methods=['POST'])
def update_threshold():
    global GLOBAL_GRAYSCALE_THRESHOLD
    val = request.json.get('threshold', 80)
    GLOBAL_GRAYSCALE_THRESHOLD = int(val)
    return jsonify({'status': 'ok'})


@app.route('/update_density', methods=['POST'])
def update_density():
    global AREA_STEP
    data = request.json
    val = data.get('density', 10)
    
    # Update the global step
    AREA_STEP = int(np.clip(val, 5, 100))
    
    # Explicitly trigger the recalculation of the coordinates
    update_area_preview()
    
    print(f"[DENSITY] Variable updated to: {AREA_STEP}", flush=True)
    return jsonify({'status': 'ok', 'area_step': AREA_STEP})

@app.route('/update_laser_time', methods=['POST'])

def update_laser_time():
    global LASER_ON_TIME_MS
    data = request.get_json()
    value = float(data.get("laser_on_time_ms", LASER_ON_TIME_MS))

    # clamp to safe software bounds
    value = max(0.1, min(value, 100.0))

    with laser_time_lock:
        LASER_ON_TIME_MS = value

    print(f"[LASER] On-time set to {LASER_ON_TIME_MS} ms", flush=True)
    return jsonify({"status": "ok", "laser_on_time_ms": LASER_ON_TIME_MS})


def run_flask_server():
    print("\n" + "="*60, flush=True)
    print("FLASK SERVER STARTING", flush=True)
    print(f"Server: http://{SERVER_IP}:{TABLET_SERVER_PORT}", flush=True)
    print(f"Rotation: {ROTATION_ANGLE_DEG} deg around ({ROTATION_CENTER_X}, {ROTATION_CENTER_Y})", flush=True)
    print("="*60 + "\n", flush=True)
    app.run(host=SERVER_IP, port=TABLET_SERVER_PORT, debug=False, threaded=True)

# --------------------------------------------
# ROTATION TRANSFORMATION
# --------------------------------------------
def rotate_point(x, y, angle_rad, cx, cy):
    x_shifted = x - cx
    y_shifted = y - cy
    
    cos_a = np.cos(angle_rad)
    sin_a = np.sin(angle_rad)
    x_rot = x_shifted * cos_a - y_shifted * sin_a
    y_rot = x_shifted * sin_a + y_shifted * cos_a
    
    x_final = x_rot + cx
    y_final = y_rot + cy
    
    return (x_final, y_final)

def rotate_points_batch(points, angle_rad, cx, cy):
    return [rotate_point(x, y, angle_rad, cx, cy) for x, y in points]

# --------------------------------------------
# HSV LASER DETECTION
# --------------------------------------------
def find_laser_spot_hsv(frame):
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    l1, u1 = np.array([0, 50, 50]), np.array([10, 255, 255])
    l2, u2 = np.array([160, 50, 50]), np.array([180, 255, 255])
    mask = cv2.addWeighted(cv2.inRange(hsv, l1, u1), 1.0, cv2.inRange(hsv, l2, u2), 1.0, 0)
    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if cnts:
        c = max(cnts, key=cv2.contourArea)
        if cv2.contourArea(c) > 2:
            M = cv2.moments(c)
            if M["m00"] != 0:
                return (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))
    return None

# --------------------------------------------
# AREA & BOUNDARY PROCESSING
# --------------------------------------------
def get_area_points(polygon, step):
    """Generate grid points inside polygon using the provided step size"""
    pts_to_send = []
    # Ensure polygon is the correct shape for OpenCV
    if not isinstance(polygon, np.ndarray):
        polygon = np.array(polygon, dtype=np.int32)
        
    x, y, w, h = cv2.boundingRect(polygon)
    s = int(step) # Force integer step
    
    for j in range(y, y + h, s):
        for i in range(x, x + w, s):
            # The 'False' parameter means we just want to know if it's inside (True/False)
            if cv2.pointPolygonTest(polygon, (float(i), float(j)), False) >= 0:
                pts_to_send.append((i, j))
    return pts_to_send


def get_area_points_hex(contour, step):
    """
    Generate hexagonally packed points inside a closed contour.
    contour: Nx2 numpy array (must be closed)
    step: spacing between points (controls density)
    """
    contour = contour.astype(np.int32)

    # Bounding box
    x, y, w, h = cv2.boundingRect(contour)

    points = []

    dx = step
    dy = step * np.sqrt(3) / 2  # hex vertical spacing

    row = 0
    y_pos = y

    while y_pos <= y + h:
        # Offset every other row
        x_offset = dx / 2 if row % 2 else 0
        x_pos = x + x_offset

        while x_pos <= x + w:
            if cv2.pointPolygonTest(contour, (x_pos, y_pos), False) >= 0:
                points.append((int(x_pos), int(y_pos)))
            x_pos += dx

        y_pos += dy
        row += 1

    return points


def update_area_preview():
    """Recompute preview dots. Fills area for shapes, follows path for lines."""
    global area_preview_points, last_active_contour, AREA_STEP

    if last_active_contour is None:
        with area_preview_lock:
            area_preview_points = []
        return

    # A contour is "Closed" only if the first and last points are identical
    is_closed = np.array_equal(last_active_contour[0], last_active_contour[-1])

    if is_closed:
        # Only draw inside the green area if it's a closed shape
        new_pts = get_area_points_hex(last_active_contour, AREA_STEP)
    else:
        # It's an open line: Only generate points ON the line path
        new_pts = get_path_points(last_active_contour, AREA_STEP)
    
    with area_preview_lock:
        area_preview_points = new_pts
        
    print(f"[PREVIEW] Mode: {'FILL' if is_closed else 'PATH'}, Points: {len(new_pts)}")
    

def distance(p1, p2):
    return math.hypot(int(p1[0]) - int(p2[0]), int(p1[1]) - int(p2[1]))

def get_sampled_contour(contour, min_jump_dist):
    points = np.array(contour).reshape(-1, 2)
    if not points.any():
        return []
    
    sampled = [tuple(points[0])]
    last_point = points[0]
    
    for pt in points[1:]:
        if distance(last_point, pt) >= min_jump_dist:
            sampled.append(tuple(pt))
            last_point = pt
    
    return sampled

def get_path_points(points_list, step):
    """Generates points strictly along a path (line) based on density step"""
    path_pts = []
    if len(points_list) < 2:
        return path_pts
        
    for i in range(len(points_list) - 1):
        p1 = points_list[i]
        p2 = points_list[i+1]
        dist = distance(p1, p2)
        
        # Calculate steps for this specific segment
        num_steps = max(1, int(dist / max(1, step)))
        for j in range(num_steps):
            t = j / num_steps
            px = int(p1[0] + t * (p2[0] - p1[0]))
            py = int(p1[1] + t * (p2[1] - p1[1]))
            path_pts.append((px, py))
            
    # Add the very last point
    path_pts.append(tuple(points_list[-1]))
    return path_pts
def send_batch_to_server(points_list, daq_socket):
    if not daq_socket or not points_list:
        return
    
    rotated_points = rotate_points_batch(points_list, ROTATION_ANGLE_RAD, ROTATION_CENTER_X, ROTATION_CENTER_Y)
    
    with socket_lock:
        try:
            daq_socket.sendall(b"BATCH_START\n")
            data_string = ";".join(["{0},{1}".format(int(x), int(y)) for x, y in rotated_points])
            daq_socket.sendall(data_string.encode('ascii') + b"\n")
            print(f"[BATCH] Sent {len(rotated_points)} rotated points", flush=True)
        except Exception as e:
            print(f"Batch error: {e}")

def find_dark_spots(frame):
    global GLOBAL_GRAYSCALE_THRESHOLD, detected_contours
    
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    _, mask = cv2.threshold(gray, GLOBAL_GRAYSCALE_THRESHOLD, 255, cv2.THRESH_BINARY_INV)
    kernel = np.ones((3, 3), np.uint8)
    mask = cv2.dilate(cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel), kernel, iterations=1)
    detected, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    detected_contours = [c for c in detected if MIN_AREA < cv2.contourArea(c) < MAX_AREA]
    return detected_contours

def get_line_points(start_pt, end_pt, step):
    """Discretize a line into points based on the density (step)"""
    x1, y1 = start_pt
    x2, y2 = end_pt
    dist = distance(start_pt, end_pt)
    
    # Calculate how many points fit based on current AREA_STEP
    num_points = max(2, int(dist / max(1, step)))
    
    pts = []
    for i in range(num_points):
        t = i / (num_points - 1)
        px = int(x1 + t * (x2 - x1))
        py = int(y1 + t * (y2 - y1))
        pts.append((px, py))
    return pts

def send_lasing_to_server(points_list, daq_socket, DWELL_MS):
    if not daq_socket or not points_list:
        print("[LASING] Aborted: No socket or no points.")
        return

    # Use the global value to be safe
    with laser_time_lock:
        current_dwell = LASER_ON_TIME_MS

    with socket_lock:
        try:
            # Add \n to every command so the server sees it!
            daq_socket.sendall(b"LASING_START\n")
            
            dwell_msg = f"DWELL_MS={current_dwell:.3f}\n"
            daq_socket.sendall(dwell_msg.encode("ascii"))

            # Send points individually with \n for better server parsing
            for x, y in points_list:
                rx, ry = rotate_point(x, y, ROTATION_ANGLE_RAD, ROTATION_CENTER_X, ROTATION_CENTER_Y)
                msg = f"{int(rx)},{int(ry)}\n"
                daq_socket.sendall(msg.encode("ascii"))

            daq_socket.sendall(b"LASING_END\n")
            print(f"[LASING] Sent {len(points_list)} points.")
        except Exception as e:
            print(f"[LASING] Socket error: {e}")
            
# --------------------------------------------
# TOUCH INPUT HANDLER
# --------------------------------------------
def calculate_path_length(points):
    if len(points) < 2:
        return 0
    return sum(distance(points[i-1], points[i]) for i in range(1, len(points)))

def handle_touch_down(x, y):
    global drawing, current, touch_active, touch_start_pos, touch_current_path
    global finished_polys, last_active_contour, detected_contours
    
    if MANUAL_CALIBRATION_MODE:
        return
    
    pt = (int(x), int(y))
    
    for detected_c in detected_contours:
        if cv2.pointPolygonTest(detected_c, pt, False) >= 0:
            poly_arr = np.array(detected_c, dtype=np.int32).reshape(-1, 2)
            # ðŸ”’ FORCE CLOSE detected contour
            if not np.array_equal(poly_arr[0], poly_arr[-1]):
                poly_arr = np.vstack([poly_arr, poly_arr[0]])
            finished_polys.append(poly_arr)
            last_active_contour = poly_arr
            update_area_preview()   # â† KEEP
            print(f"[ACTIVE] Detected contour selected, preview updated", flush=True)
            send_batch_to_server(get_sampled_contour(poly_arr, MIN_JUMP_DIST), daq_socket)
            return

    
    touch_active = True
    touch_start_pos, touch_current_path = pt, [pt]
    drawing = True
    current = []
    
    with contour_lock:
        contours.clear()
        contours.append(current)
    current.append(pt)

def handle_touch_move(x, y):
    global current, touch_current_path
    
    if not touch_active or MANUAL_CALIBRATION_MODE:
        return
    
    pt = (int(x), int(y))
    touch_current_path.append(pt)
    
    if not current or distance(current[-1], pt) >= MIN_DIST:
        with contour_lock:
            current.append(pt)

def handle_touch_up(x, y):
    global drawing, current, touch_active, touch_start_pos
    global finished_polys, last_active_contour
    
    if not touch_active or MANUAL_CALIBRATION_MODE:
        return
    
    touch_active = False
    drawing = False
    
    if len(current) > 2:
        # Check start-to-end distance vs threshold
        gap = distance(current[0], current[-1])
        
        if gap < CLOSED_THRESHOLD:
            # Force close the contour
            current.append(current[0])
            print(f"[SHAPE] Closed: gap({int(gap)}) < threshold({CLOSED_THRESHOLD})")
        else:
            print(f"[LINE] Open: gap({int(gap)}) > threshold({CLOSED_THRESHOLD})")
            
        poly_arr = np.array(current, dtype=np.int32)
        finished_polys.append(poly_arr)
        last_active_contour = poly_arr
        
        # Re-calculate the red dots (preview)
        update_area_preview()
        
        # Send preview to galvos (without laser)
        send_batch_to_server(get_sampled_contour(poly_arr, MIN_JUMP_DIST), daq_socket)
    
    current = []

# --------------------------------------------
# CALIBRATION
# --------------------------------------------
def calibrate_galvo_camera():
    global daq_socket, MANUAL_CALIBRATION_MODE, CALIBRATION_DATA_MAP, CALIBRATION_PIXEL_POINTS, cap
    
    if not daq_socket or cap is None:
        print("ERROR: DAQ or camera not initialized")
        return False
    
    MANUAL_CALIBRATION_MODE = True
    CALIBRATION_DATA_MAP.clear()
    CALIBRATION_PIXEL_POINTS.clear()
    
    with socket_lock:
        try:
            # 1. Notify Start
            daq_socket.sendall(b"CALIBRATION_START\n")
            time.sleep(0.5)

            cx, cy = (GALVO_MAX_X + GALVO_MIN_X)//2, (GALVO_MAX_Y + GALVO_MIN_Y)//2
            xs = np.linspace(GALVO_MIN_X, GALVO_MAX_X, CROSS_SIZE, dtype=np.int32)
            ys = np.linspace(GALVO_MIN_Y, GALVO_MAX_Y, CROSS_SIZE, dtype=np.int32)
            gal_pts = [(cx, int(y)) for y in ys] + [(int(x), cy) for x in xs if int(x) != cx]
            
            # 2. Project Cross and Capture
            for x_dac, y_dac in gal_pts:
                if not MANUAL_CALIBRATION_MODE: break
                
                rotated = rotate_point(x_dac, y_dac, ROTATION_ANGLE_RAD, ROTATION_CENTER_X, ROTATION_CENTER_Y)
                daq_socket.sendall(f"{int(rotated[0])},{int(rotated[1])}\n".encode('ascii'))
                
                # Wait for mirrors to settle and camera to catch up
                time.sleep(0.2) 
                
                found_pt = None
                start_search = time.time()
                while (time.time() - start_search) < 1.5:
                    ret, frame = cap.read()
                    if not ret: break
                    
                    spot = find_laser_spot_hsv(frame)
                    if spot:
                        found_pt = spot
                        CALIBRATION_PIXEL_POINTS.append(spot)
                        break
                
                if found_pt:
                    CALIBRATION_DATA_MAP.append(found_pt)
                    print(f"Captured: DAC({x_dac},{y_dac}) -> Pixel{found_pt}")

            # 3. Dump results to Server
            print(f"Sending {len(CALIBRATION_DATA_MAP)} points to server...")
            daq_socket.sendall(b"PIXEL_DUMP_START\n")
            time.sleep(0.1)
            
            for px, py in CALIBRATION_DATA_MAP:
                msg = "{0},{1}\n".format(int(px), int(py))
                daq_socket.sendall(msg.encode('ascii'))
            
            daq_socket.sendall(b"PIXEL_DUMP_END\n")
            print("Calibration stream finished successfully")

        except Exception as e:
            print(f"Calibration Socket Error: {e}")
    
    MANUAL_CALIBRATION_MODE = False
    return True

# -------------------------------------------- 
# MAIN EXECUTION
# --------------------------------------------
try:
    daq_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    daq_socket.connect((HOST, PORT))
    daq_socket.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
    print("Connected to DAQ server")
except:
    daq_socket = None
    print("Warning: Could not connect to DAQ server")

flask_thread = threading.Thread(target=run_flask_server, daemon=True)
flask_thread.start()

cap = cv2.VideoCapture(1)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1440)

cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)

while running:
    ret, frame = cap.read()
    if not ret:
        break

    if not MANUAL_CALIBRATION_MODE:
        detected_contours = find_dark_spots(frame)
        overlay = frame.copy()

        for poly in finished_polys:
            if len(poly) >= 3 and distance(poly[0], poly[-1]) < CLOSED_THRESHOLD:
                cv2.fillPoly(overlay, [poly], (0, 255, 0))
                cv2.polylines(frame, [poly], True, (0, 255, 0), 2)
            else:
                cv2.polylines(frame, [poly], False, (0, 255, 0), 2)

        cv2.addWeighted(overlay, 0.4, frame, 0.6, 0, frame)

        with contour_lock:
            for cnt in contours:
                if len(cnt) >= 2:
                    pts = np.array(cnt, np.int32).reshape((-1, 1, 2))
                    cv2.polylines(frame, [pts], False, (255, 0, 255), 3)

        for pt in CALIBRATION_PIXEL_POINTS:
            cv2.drawMarker(frame, pt, (255, 0, 0), cv2.MARKER_CROSS, 20, 3)
        
        cv2.drawContours(frame, detected_contours, -1, (0, 0, 255), 2)
    
    if MANUAL_CALIBRATION_MODE:
        for pt in CALIBRATION_PIXEL_POINTS:
            cv2.drawMarker(frame, pt, (255, 0, 0), cv2.MARKER_CROSS, 20, 3)
    
    with area_preview_lock:
            # Create a local copy to iterate over so the list can change in the background
            current_preview = list(area_preview_points)
        
    for (px, py) in current_preview:
            # Use a smaller radius for high density to avoid a solid red blob
        radius = 5 
        cv2.circle(frame, (int(px), int(py)), radius, (0, 0, 255), -1)

    with video_lock:
        output_frame = frame.copy()
    
    # with area_preview_lock:
    #     current_preview = list(area_preview_points)
    # 
    # for (px, py) in current_preview:
    #     radius = max(2, int(AREA_STEP / 3))
    #     cv2.circle(frame, (int(px), int(py)), radius, (0, 0, 255), -1)

    cv2.imshow(WINDOW_NAME, frame)
    
    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'): 
        running = False
    elif key == ord('c'): 
        with contour_lock:
            finished_polys.clear()
            contours.clear()
            last_active_contour = None
        with area_preview_lock:
            area_preview_points.clear()
        print("Cleared")
    elif key == ord('a'): 
        threading.Thread(target=calibrate_galvo_camera, daemon=True).start()
    elif key == ord('l'):
        if last_active_contour is not None:
            with area_preview_lock:
                area_pts = list(area_preview_points)
            send_batch_to_server(area_pts, daq_socket)

if daq_socket:
    daq_socket.close()
cap.release()
cv2.destroyAllWindows()
